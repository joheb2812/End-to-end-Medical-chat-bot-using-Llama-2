{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e2f44ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joheb.dani\\AppData\\Local\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "import pinecone\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01cee623",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"pcsk_3h5pvh_UEkz4nMcwLcdcdmQNkv8XPzWxh7MhtmztTAqMveMEKpNReKYTdC89i4qzPMCZeJ\"\n",
    "PINECONE_API_ENV = \"us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1db8031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from the PDF files\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data, \n",
    "                    glob=\"*.pdf\", \n",
    "                    loader_cls=PyPDFLoader,\n",
    "                    show_progress=True)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ff8457d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:39<00:00, 39.45s/it]\n"
     ]
    }
   ],
   "source": [
    "extracted_data = load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cdcc7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40f4824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "384a96c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text chunks: 5859\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(f\"Number of text chunks: {len(text_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a31f9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download embedding model\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "035f1eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from sentence-transformers) (4.46.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from sentence-transformers) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.24.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\joheb.dani\\appdata\\local\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# embeddings = download_hugging_face_embeddings()\n",
    "\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c5481ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joheb.dani\\AppData\\Local\\Temp\\ipykernel_11728\\3777190553.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b0ba85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b98a74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello World!\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30499d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec6db0cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "init is no longer a top-level attribute of the pinecone package.\n\nPlease create an instance of the Pinecone class instead.\n\nExample:\n\n    import os\n    from pinecone import Pinecone, ServerlessSpec\n\n    pc = Pinecone(\n        api_key=os.environ.get(\"PINECONE_API_KEY\")\n    )\n\n    # Now do stuff\n    if 'my_index' not in pc.list_indexes().names():\n        pc.create_index(\n            name='my_index', \n            dimension=1536, \n            metric='euclidean',\n            spec=ServerlessSpec(\n                cloud='aws',\n                region='us-west-2'\n            )\n        )\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpinecone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPINECONE_API_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPINECONE_API_ENV\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedical-chatbot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m docsearch \u001b[38;5;241m=\u001b[39m Pinecone\u001b[38;5;241m.\u001b[39mfrom_texts([t\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m text_chunks],embeddings, index_name\u001b[38;5;241m=\u001b[39mindex_name)\n",
      "File \u001b[1;32mc:\\Users\\joheb.dani\\AppData\\Local\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\pinecone\\deprecation_warnings.py:39\u001b[0m, in \u001b[0;36minit\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     12\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124m    import os\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124m    from pinecone import Pinecone, ServerlessSpec\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124m        )\u001b[39m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     32\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124minit is no longer a top-level attribute of the pinecone package.\u001b[39m\n\u001b[0;32m     33\u001b[0m \n\u001b[0;32m     34\u001b[0m \u001b[38;5;124mPlease create an instance of the Pinecone class instead.\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mexample\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(msg)\n",
      "\u001b[1;31mAttributeError\u001b[0m: init is no longer a top-level attribute of the pinecone package.\n\nPlease create an instance of the Pinecone class instead.\n\nExample:\n\n    import os\n    from pinecone import Pinecone, ServerlessSpec\n\n    pc = Pinecone(\n        api_key=os.environ.get(\"PINECONE_API_KEY\")\n    )\n\n    # Now do stuff\n    if 'my_index' not in pc.list_indexes().names():\n        pc.create_index(\n            name='my_index', \n            dimension=1536, \n            metric='euclidean',\n            spec=ServerlessSpec(\n                cloud='aws',\n                region='us-west-2'\n            )\n        )\n\n"
     ]
    }
   ],
   "source": [
    "pinecone.init(api_key=PINECONE_API_KEY,\n",
    "                environment=PINECONE_API_ENV)\n",
    "index_name = \"medical-chatbot\"\n",
    "\n",
    "docsearch = Pinecone.from_texts([t.page_content for t in text_chunks],embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3668e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Initialize Pinecone client\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"medical-chatbot\"\n",
    "\n",
    "# If the index doesn't exist, create it\n",
    "if index_name not in [index.name for index in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,  \n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Now connect to the index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# For LangChain integration\n",
    "from langchain_community.vectorstores import Pinecone as PineconeStore\n",
    "\n",
    "docsearch = PineconeStore.from_texts(\n",
    "    [t.page_content for t in text_chunks],\n",
    "    embeddings,\n",
    "    index_name=index_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5c1ebee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result [Document(page_content='Purpose\\nAllergy is a reaction of the immune system. Nor-\\nmally, the immune system responds to foreign microor-\\nganisms and particles, like pollen or dust, by producing\\nspecific proteins called antibodies that are capable of\\nbinding to identifying molecules, or antigens, on the\\nforeign organisms. This reaction between antibody and\\nantigen sets off a series of reactions designed to protect\\nthe body from infection. Sometimes, this same series of'), Document(page_content='reaction. Allergic rhinitis is characterized by an itchy,\\nrunny nose, often with a scratchy or irritated throat due\\nto post-nasal drip. Inflammation of the thin membrane\\ncovering the eye (allergic conjunctivitis) causes redness,\\nirritation, and increased tearing in the eyes. Asthma caus-\\nes wheezing, coughing, and shortness of breath. Symp-\\ntoms of food allergies depend on the tissues most sensi-\\ntive to the allergen and whether the allergen spread sys-'), Document(page_content='KEY TERMS\\nAllergen —A substance that provokes an allergic\\nresponse.\\nAnaphylaxis—Increased sensitivity caused by pre-\\nvious exposure to an allergen that can result in\\nblood vessel dilation (swelling) and smooth mus-\\ncle contraction. Anaphylaxis can result in sharp\\nblood pressure drops and difficulty breathing.\\nAntibody —A specific protein produced by the\\nimmune system in response to a specific foreign\\nprotein or particle called an antigen.\\nAntigen —A foreign protein to which the body')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Pinecone as PineconeStore\n",
    "\n",
    "# If index already exists, load it\n",
    "docsearch = PineconeStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "# Now run your query\n",
    "query = \"What are Allergies\"\n",
    "docs = docsearch.similarity_search(query, k=3)\n",
    "\n",
    "print(\"Result\", docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7799c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32b816eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs={\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa11da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(model=\"model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':512,\n",
    "                          'temperature':0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffedf7a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for RetrievalQA\nretriever\n  field required (type=value_error.missing)\nretrriever\n  extra fields not permitted (type=value_error.extra)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m qa \u001b[38;5;241m=\u001b[39m \u001b[43mRetrievalQA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_chain_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstuff\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretrriever\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocsearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_source_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain_type_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchain_type_kwargs\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joheb.dani\\AppData\\Local\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\chains\\retrieval_qa\\base.py:117\u001b[0m, in \u001b[0;36mBaseRetrievalQA.from_chain_type\u001b[1;34m(cls, llm, chain_type, chain_type_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m _chain_type_kwargs \u001b[38;5;241m=\u001b[39m chain_type_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m    114\u001b[0m combine_documents_chain \u001b[38;5;241m=\u001b[39m load_qa_chain(\n\u001b[0;32m    115\u001b[0m     llm, chain_type\u001b[38;5;241m=\u001b[39mchain_type, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_chain_type_kwargs\n\u001b[0;32m    116\u001b[0m )\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcombine_documents_chain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_documents_chain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joheb.dani\\AppData\\Local\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:215\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     emit_warning()\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joheb.dani\\AppData\\Local\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:215\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     emit_warning()\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joheb.dani\\AppData\\Local\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain_core\\load\\serializable.py:113\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    112\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joheb.dani\\AppData\\Local\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\pydantic\\main.py:347\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 2 validation errors for RetrievalQA\nretriever\n  field required (type=value_error.missing)\nretrriever\n  extra fields not permitted (type=value_error.extra)"
     ]
    }
   ],
   "source": [
    "qa=RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=docsearch.as_retriever(search_kwargs={'k': 2}),\n",
    "    return_source_documents=True, \n",
    "    chain_type_kwargs=chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d37950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
